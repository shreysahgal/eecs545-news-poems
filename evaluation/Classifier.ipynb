{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#poetry_df = pd.read_csv(\"../data/poetry/kaggle_poem_dataset.csv\").drop(['Unnamed: 0'],axis=1)\n",
    "#news_df = pd.read_csv('../data/news/news_summary_more.csv')\n",
    "\n",
    "poetry_df = pd.read_csv(\"../data/poetry/kaggle_poem_dataset.csv\").drop(['Unnamed: 0'],axis=1)\n",
    "news_df = pd.read_csv('../data/news_summary_more.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_pos(doc):\n",
    "    pos_list = [p[1] for p in pos_tag(word_tokenize(doc),tagset='universal')]  \n",
    "    return pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "poetry_df['pos'] = poetry_df['Content'].apply(lambda row: token_pos(row), convert_dtype=False)\n",
    "poetry_df['len'] = poetry_df['pos'].apply(lambda row: len(row), convert_dtype=False)\n",
    "news_df['pos'] = news_df[\"text\"].apply(lambda row: token_pos(row), convert_dtype=False)\n",
    "news_df['len'] = news_df[\"pos\"].apply(lambda row: len(row), convert_dtype=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poetry_df=poetry_df[poetry_df['len']<100]\n",
    "news_df = news_df[:len(poetry_df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2864"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(poetry_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62.983938547486034, 68.4895251396648)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(poetry_df2['len']), np.mean(news_df2['len'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the classifier: doc_embedding, deep neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### documents are transformed into GPT-2 vectors\n",
    "\n",
    "poetry_df['doc_embedding'] = poetry_df[\"Content\"].apply(lambda row: sbert_model.encode(row),convert_dtype = False )\n",
    "news_df['doc_embedding'] = news_df[\"text\"].apply(lambda row: sbert_model.encode(row),convert_dtype = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([poetry_df['doc_embedding'],news_df['doc_embedding']])\n",
    "X = X.values\n",
    "X = np.stack(X)\n",
    "\n",
    "y = ['0']*poetry_df.shape[0] + ['1']*news_df.shape[0]\n",
    "y = np.array(y).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "162/162 [==============================] - 1s 1ms/step - loss: 0.1491 - accuracy: 0.9659\n",
      "Epoch 2/5\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0938 - accuracy: 0.9765\n",
      "Epoch 3/5\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0353 - accuracy: 0.9919\n",
      "Epoch 4/5\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0255 - accuracy: 0.9942\n",
      "Epoch 5/5\n",
      "162/162 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 0.9961\n",
      "18/18 [==============================] - 0s 1ms/step - loss: 0.0146 - accuracy: 0.9948\n",
      "Accuracy: 99.48\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.10, random_state=40)\n",
    "X_train.shape\n",
    "\n",
    "epochs = 5\n",
    "#batch_size =2000\n",
    "\n",
    "opt = tf.optimizers.Adam(learning_rate=0.0005)\n",
    "model = Sequential()\n",
    "model.add(Dense(150, input_dim=768, activation='tanh'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1, activation='tanh'))\n",
    "#model.compile(loss=poem_loss, optimizer=opt, metrics=['accuracy'])\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=epochs)\n",
    "\n",
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "#acc = np.sum(np.round(model.predict(X_test))==y_test)/tf.reshape(y_test, [-1]).shape[0]\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classifier_model.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on the evaluation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('classifier_model.h5')\n",
    "test = pd.read_csv('eval_data.csv')\n",
    "y_test = [0]*len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test[\"poem\"].apply(lambda row: sbert_model.encode(row),convert_dtype = False )\n",
    "X_test = X_test.values\n",
    "X_test = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 120ms/step - loss: 0.4144 - accuracy: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.41441434621810913, 0.875]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
